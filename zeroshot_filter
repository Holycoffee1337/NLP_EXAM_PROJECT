from transformers import pipeline
from datasets import load_dataset
import numpy as np
import pandas as pd

class ZeroShotFilter:
    def __init__(self, 
                 model_name='facebook/bart-large-mnli', 
                 candidate_labels=[
                                    'World',
                                    'Sport',
                                    'Businees',
                                    'Technology',
                                    'Entertainment'
                                    ]
                ):
        """
        Initialize Zero-Shot Text Classifier for Soccer-Related Content
        Default model is: facebook/bart-large-mnli
        Default labels are: World, Sport, Business, Technology, Entertainment

        Args:
            model_name (str): Transformer model for zero-shot classification
            candidate_labels (list): Predefined labels for classification
        """
        # Initialize zero-shot classification pipeline
        self.classifier = pipeline(
            "zero-shot-classification", 
            model=model_name
        )
        
        self.candidate_labels = candidate_labels

    def filter_texts(self, texts, topics, threshold=0.5):
        """
        Filter texts likely to be relevant to given topics of interest
        Args:
            texts (list): List of text documents to filter
            topics (list): List of topics to filter for | Must be a subset of candidate labels
            threshold (float): Probability threshold for topics related content
        
        Returns:
            DataFrame: Results
        """
        #Check if topics is a subset of self.candidate_labels
            ## Try catch?
        if not set(topics).issubset(set(self.candidate_labels)):
            raise ValueError("Topics is not a subset of candidate labels.")

        results = []
        # Classify each text
        # Loop over the texts and print progress
        for i, text in enumerate(texts):
            result = self.classifier(text, self.candidate_labels)
            
            # Print progress
                #TODO: Make this percentages?
            print(f"Processing text {i+1}/{len(texts)}")
            
            # If the full text is of interest uncomment next line
            # result["text"] = text  
            results.append(result)
        
        df = pd.DataFrame(results)
        # Filters out articles where the first label, the label with highest confidence, is not one of the topics of interest
        topics_articles = df[df["labels"].apply(lambda labels: labels[0] in topics)]
        # Filters out articles that have a confidence below the given threshold
        high_conf_articles = topics_articles[topics_articles["scores"].apply(lambda scores: scores[0] > threshold)]


        
        return high_conf_articles

"""
Eaxmple code for usage

ds = load_dataset("wangrongsheng/ag_news")
print("Starts!")
data_split = ds["train"]
data_text = data_split["text"]
subset_text = data_text[:100]  # Adjust the number for your needs

model = "MoritzLaurer/deberta-v3-large-zeroshot-v2.0"
# The candidates is a tunable hyperparameter
candidates = ["Soccer match","Match results", "World", "Bussiness news", "Science", "Technology", "Entertainment news"]
filter = ZeroShotFilter(model, candidate_labels= candidates)
topics = ['Soccer match', 'Match results']
# The threshold is a tunable hyperparameter
threshold = 0.7
# The finale dataframe containing the articles of interest
df = filter.filter_texts(subset_text, topics, threshold)
print(df)
"""

